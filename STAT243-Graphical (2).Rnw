\Sexpr{set_parent('Math241-S15.Rnw')}

\Chapter{Graphical Summaries of Data}

\section{Getting Started With \RStudio}

\begin{figure}
\begin{center}
\includegraphics[width=.85\textwidth]{images/RStudio-Welcome2}
\end{center}
\caption{Welcome to \Rstudio.}
\label{fig:Rstudio-welcome}%
\end{figure}

\RStudio{} is an integrated development environment (IDE) for \R,  
a freely available language and environment for statistical computing and graphics.
Both \R and \RStudio{} are freely available for Mac, PC, and Linux.  

We have set up an RStudio server on campus, which allows you to run R in a web browser on any computer without installing the software yourself.  Your session is restored each time you log in, so you can work on multiple computers without losing your work when you move from one to the other.  The RStudio server is the recommended interface for using R and RStudio for this course. You can access the \RStudio{} server via a web browser.  (For best results, avoid 
Internet Explorer.)

If you prefer to install R and RStudio directly on your own computer, you can get R at \url{<http://cran.r-project.org>} and RStudio at \url{<http://rstudio.org/>}.    

To access the Calvin \RStudio{} server, use the links from our course
Moodle site, or connect directly at \url{http://rstudio.calvin.edu:8787}.

\subsection{Logging in}
When you navigate to the \RStudio{} server, you will be prompted to login.  
% Your login and password are both your Calvin
% userid.  
Your login is your Calvin Gmail address, and your password is the corresponding password. 
Once you are logged in, you will see something like 
Figure~\ref{fig:Rstudio-welcome}.

% To change your password:
% \begin{enumerate}
% 	\item From the \tab{Tools} menu, select \tab{Shell...}
% 	\item
% 		Type \code{yppasswd}
% 	\item
% 		You will be prompted for your old password, then your new password twice.
% 	\item
% 		If you give a sufficiently strong new password, then
% 		you will receive notice that your password has been reset.  
% 		If there was a problem, you will see a message about it and can try again.
% 	\item
% 		Once you have reset your password, click on \tab{Close} to close the 
% 		shell and get back to \RStudio.
% \end{enumerate}

\subsection{Using R as a calculator}

Notice that \Rstudio\ divides its world into four panels.  Several of the panels
are further subdivided into multiple tabs.
The \textbf{Console} panel is where we type commands that \R\ will execute. 

\R\ can be used as a calculator.  Try typing the following commands in the console panel.
\Rindex{sqrt()}%
\Rindex{log()}%
\Rindex{log10()}%
<<arithmetic2>>=
5 + 3
15.3 * 23.4
sqrt(16)
@
You can save values to named variables for later reuse
<<variables2,tidy=FALSE>>=
product = 15.3 * 23.4       # save result
product                     # show the result
product <- 15.3 * 23.4      # <- is assignment operator, same as =
product                     
15.3 * 23.4 -> newproduct   # -> assigns to the right
newproduct
.5 * product                # half of the product
log(product)                # (natural) log of the product
log10(product)              # base 10 log of the product
log(product,base=2)         # base 2 log of the product
@

The semi-colon can be used to place multiple commands on one line.  
One frequent use of the semi-colon is to save and print a value all 
in one line of code:
<<variables-semi2,tidy=FALSE>>=
15.3 * 23.4 -> product; product    # save result and show it
@

\subsection{Loading packages}

\R\ is divided up into packages.  You can think of the packages as software toolkits designed to do 
particular jobs.  A few of these, known as ``base \R", are loaded every time you
run \R, but most have to be selected.  This way you only have as much of \R\ as you
need.  There are two steps to follow before you can use a package in \R :

\begin{enumerate}
\item{Install the package.} This operation downloads the relevant files to your computer, and lets \R\ know where they are located.  It does \textit{not} give the current \R\ session permission to use the tools contained in the package!  The packages you will need for work in this course have already been installed on the Calvin \Rstudio\ server. For this course, you will probably not need to install any packages yourself, unless you are using a local copy of \R\ and \RStudio\ installed on your own computer.  If you need to install packages, an easy way to do it is to use the \textbf{Packages} tab in the lower right panel of \RStudio. Just click on \textbf{Install} (upper left corner of the \textbf{Packages} tab) and then type the name of the package.
\item{Load the package.} This operation gives the current \R\ session permission to access and use the tools contained in the package.  Even if you are using the \RStudio server, you will often need to load required packages at the beginning of each \R\ session.  There are several ways to load packages, as detailed below.
\end{enumerate}

In the \tab{Packages} tab, check the boxes next to the following packages to
load them:
\begin{itemize}
	\item \pkg{mosaic}  (a package from Project MOSAIC; this should already be loaded)
	\item \pkg{DAAG}  (a package that goes with the book \textit{Data Analysis and Graphics};
		probably not loaded, check the box to load it.)
\end{itemize}
You an also load packages by typing, for example
<<load-package>>=
require(DAAG)       # loads the DAAG package if it is not already loaded
@

\subsection{Four Things to Know About \R}
\begin{enumerate}
\item \R\ is case-sensitive

If you mis-capitalize something in \R, it won't do what you want.

\item 
Functions in \R\ use the following syntax:
<<function-syntax,eval=FALSE>>=
functionname( argument1, argument2, ... )
@
\vspace{-5mm}
\begin{itemize}
\item The arguments are \underline{always} \emph{surrounded by (round) parentheses} and 
\emph{separated by commas}.

Some functions (like \function{data()}) 
have no required arguments, but you still need the parentheses.

\item
If you type a function name without the parentheses, you will see the \emph{code} for that
function printed out to the console window -- which probably isn't what you want at this point.
\end{itemize}
\item
TAB completion and arrows can improve typing speed and accuracy.

If you begin typing a command and hit the TAB key, \R\ will show you a list of
possible ways to complete the command.  If you hit TAB after the opening
parenthesis of a function, it will show you the list of arguments it expects.
The up and down arrows can be used to retrieve past commands.
\item Hit ESCAPE to break out of a mess.
	
	If you get into some sort of mess typing (usually indicated by extra '$+$' 
	signs along the left edge, indicating that \R\ is waiting for more 
	input -- perhaps because you have some sort of error in what has gone before), 
	you can hit the escape key to get back to a clean prompt.
\end{enumerate}


\section{Data in \R}

\subsection{Data Frames}
Most often, data sets in \R\ are stored in a structure called a 
\term{data frame}.  A data frame is designed to hold ``rectangular data".  The people or things
being measured or observed are called \term{observational units} (or subjects or cases when 
they are people).  For measurements collected over time, the observational units would be the individual 
time-points at which data points were collected. Each observational unit is represented by one row in the data frame.
The different pieces of information recorded for each observational unit are stored in
separate columns, called \term{variables}.  

\subsection{Data in Packages}
There are a number of data sets built into \R\
and many more that come in various add-on packages.  

You can see a list of data sets in a particular package like this:
<<datasets,eval=FALSE>>=
data(mosaic)
@

You can find a longer list of all data sets available in any loaded package
using 
<<eval=FALSE>>=
data()
@


\subsection{The HELPrct data set}
The \dataframe{HELPrct} data frame from the \pkg{mosaic} package
contains data from the Health Evaluation and Linkage to Primary Care
randomized clinical trial.  You can find out more about the study and
the data in this data frame by typing
<<HELPrcthelp,eval=FALSE,tidy=FALSE>>=
?HELPrct
@

Among other things, this will tell us something about the subjects (observational units) in
this study:
\begin{quote}
	Eligible subjects were adults, who spoke Spanish or English, reported
	alcohol, heroin or cocaine as their first or second drug of choice, resided
	in proximity to the primary care clinic to which they would be referred or
	were homeless. Patients with established primary care relationships they
	planned to continue, significant dementia, specific plans to leave the
	Boston area that would prevent research participation, failure to provide
	contact information for tracking purposes, or pregnancy were excluded.

Subjects were interviewed at baseline during their detoxification stay and
follow-up interviews were undertaken every 6 months for 2 years.
\end{quote}

It is often handy to look at the first few rows of a data frame.  It will
show you the names of the variables and the kind of data in them:
<<headHELP>>=
head(HELPrct)
dim(HELPrct)
@
The commands and \R\ output above tell us that there are \Sexpr{nrow(HELPrct)} observational
units in this data set and \Sexpr{ncol(HELPrct)} variables.
That's plenty of variables to get us started with exploration of data.

\subsection{The KidsFeet data set}
Here is another data set in the \pkg{mosaic} package:
<<>>=
head(KidsFeet)
@

\subsection{The oldfaith data set}
A final example data set comes from the \pkg{alr3} package.  This package is probably not 
loaded (unless you already loaded it).  You can load it from the \tab{Packages} tab or
by typing the command
<<>>=
require(alr3)
@
Once you have done that, you will have access to the data set containing information about
eruptions of Old Faithful, a geyser in Yellowstone National Park.
<<>>=
head(oldfaith)
@

If you want to know the size of your data set, you can ask it how many rows and columns it has
with
\function{nrow}, \function{ncol}, or \function{dim}:
<<>>=
nrow(oldfaith)
ncol(oldfaith)
dim(oldfaith)
@
In this case we have 270 observations of each of two variables.
In a data frame, the observational units are always in the rows and the variables
are always in the columns.  If you create data for use in \R\ (or most other 
statistical packages), you need to make sure your data are also in this shape.


\subsection{Using your own data}

We will postpone for now a discussion about getting your own data into \RStudio,
but any data you can get into a reasonable format (like csv) can be imported
into \RStudio\ pretty easily.

\section{Graphing the Distribution of One Variable}

A \textbf{distribution} tells which values a variable takes on, 
and with what frequency.  That is, the distribution answers two 
questions:
\begin{itemize}
	\item What values?  
	\item How often?
\end{itemize}

Several standard statistical graphs can help us see 
distributions visually.  

The general syntax for making a graph or numerical summary
of one variable in a data frame is
<<eval=FALSE>>=
plotname( ~ variable, data=dataName )
@
In other words, there are three pieces of information we must provide to 
\R\ in order to get the plot we want:
\begin{itemize}
	\item
		The kind of plot (\function{histogram()}, \function{bargraph()}, 
		\function{densityplot()}, \function{bwplot()}, etc.) 
	\item
		The name of the variable
	\item
		The name of the data frame this variable is a part of.
\end{itemize}

Note: The same syntax works for numerical summaries as well -- thanks to the \pkg{mosaic}
package we can apply the same syntax for 
		\function{mean}, \function{median}, \function{sd},
		\function{var}, \function{max}, \function{min}, etc.
		Later we will use this syntax again to fit linear and 
		nonlinear models to data.

\subsection{Histograms (and density plots) for quantitative variables}

Histograms are a way of displaying the distribution of a quantitative 
variable.


Here are a couple examples:
<<histogram>>=
histogram( ~ Duration, data=oldfaith )
histogram( ~ age, data=HELPrct )
@

We can control the (approximate) number of bins using the \option{nint} 
argument, which may be abbreviated as \option{n}.
The number of bins (and to a lesser extent the positions of the bins)
can make a histogram look quite different.
<<histogram2, fig.width=3,out.width='.3\\textwidth'>>=
histogram( ~ Duration, data=oldfaith, n=15 )
histogram( ~ Duration, data=oldfaith, n=30 )
histogram( ~ Duration, data=oldfaith, n=50 )
@

The \function{histogram()}%
\footnote{The \pkg{mosaic} version of the \function{histogram()} function has some 
extra features (like the \option{width} argument) but is otherwise is very similar to 
regular \function{histogram()} function in \pkg{lattice}.}
function in the \pkg{mosaic} package lets you describe
the bins in terms of center and width instead of in terms of the number
of bins.  This is especially nice for count data.

<<xhistogram,fig.width=3,out.width=".3\\textwidth">>=
histogram( ~ Duration, data=oldfaith, width=60 )
histogram( ~ Duration, data=oldfaith, width=20 )
histogram( ~ Duration, data=oldfaith, width=5 )
@

\R\ also provides a ``smooth'' version called a density plot and a triangular version
called a frequency polygon; just change 
the function name from \function{histogram()} to 
\function{densityplot()} or 
\function{freqpolygon()}.
<<densityplot>>=
densityplot( ~ Duration, data=oldfaith )
freqpolygon( ~ Duration, data=oldfaith )
@


\subsection{The shape of a distribution}

If we make a histogram of our data, we can describe the overall shape of the distribution.
Keep in mind that the shape of a particular histogram may depend on the choice of bins.
Choosing too many or too few bins can hide the true shape of the distribution.  (When in doubt, compare several
histograms with different bin settings before you decide which one provides the most informative
summary of the data.)

Here are some words we use to describe shapes of distributions.
\begin{description}
\item[symmetric] The left and right sides are mirror images of each other.
\item[skewed] The distribution stretches out farther in one direction than in the other.  
(We say the distribution is skewed toward the long tail. So right-skewed 
(also known as positive-skewed)
data have a ``fat right tail" -- more observations of larger values than of small ones.)
\item[uniform] The heights of all the bars are (roughly) the same.  
(So the data are equally likely to be anywhere within some range.)
\item[unimodal] There is one major ``bump'' where there is a lot of data.
\item[bimodal] There are two ``bumps''.
\item[outlier] An observation that does not fit the overall pattern of the rest of 
the data.
\end{description}



We'll learn about another graph used for quantitative variables 
(a boxplot, \function{bwplot()} in \R) soon.

\subsection{Bar graphs for categorical variables}

Bar graphs are a way of displaying the distribution of a categorical variable.

<<bargraph>>=
bargraph( ~ substance, data=HELPrct) 
bargraph( ~ substance, data=HELPrct, horizontal=TRUE )
@

A side note: we will be unlikely to use pie charts in this course.
Many data analysts argue that pie charts are difficult to read and interpret,
and often use space ineffectively, especially if they are divided into more than two slices.  Unless you are \textit{sure} 
there is a good reason to use one, don't.

\section{Looking at Multiple Variables at Once}

\subsection{Conditional plots}
The formula for a \pkg{lattice} plot can be extended to create multiple
panels based on a ``condition'', often given by another variable.  The 
general syntax for this becomes
<<eval=FALSE>>=
plotname( ~ variable | condition, data=dataName )
@

For example, we might like to see how the ages of men and women compare 
in the HELP study, or whether the distribution of weights of male mosquitoes 
is different from the distribution for females.

<<compare-ages>>=
histogram( ~ age | sex, HELPrct, width=5)
densityplot( ~ length | sex, KidsFeet )
@


We can do the same thing for bar graphs.

<<substance-by-sex>>=
bargraph( ~ substance | sex, data=HELPrct)
@

\subsection{Grouping}
Another way to look at multiple groups simultaneously is by using 
the \argument{groups} argument.  What \argument{groups} does depends a bit on the type of 
graph, but it will put the information in one panel rather than multiple panels.
Using \argument{groups} with \function{histogram()} doesn't work so well because
it is difficult to overlay histograms.%
\footnote{The \pkg{mosaic} function
\function{histogram()} does do something meaningful with \argument{groups}
in some situations.}
Density plots work better when you wish to look at the shapes of several distributions 
in a single plot panel.

Here are some examples.  We use \argument{auto.key=TRUE} to build 
a simple legend so we can tell which groups are which.
<<groups>>=
bargraph(~substance, groups=sex, data=HELPrct, auto.key=TRUE)
densityplot(~age, groups=sex, data=HELPrct, auto.key=TRUE)
@

We can even combine grouping and conditioning in the same plot.
<<groups-conditions,fig.width=6,fig.height=2.5>>=
densityplot(~age|sex, groups=substance, data=HELPrct, auto.key=TRUE)
@
<<groups-conditions2,fig.width=6,fig.height=2.5>>=
densityplot(~age|substance, groups=sex, data=HELPrct, auto.key=TRUE, layout=c(3,1))
@
This plot shows that for each substance, the age distributions of men and 
women are quite similar, but that the distributions differ from 
substance to substance.

\subsection{Scatterplots}

The most common way to look at two quantitative variables is with a 
scatter plot.  The \pkg{lattice} function for this is \function{xyplot()}, 
and the basic syntax is

<<xyplot-syntax, eval=FALSE>>=
xyplot( yvar ~ xvar, data=dataName)
@

Notice that now we have something on both sides of the \~{} since we need to tell
\R\ about two variables.  

<<xyplot1, tidy=FALSE>>=
head(iris) # data on iris plants
xyplot( Sepal.Length ~ Sepal.Width, data=iris )
@

Grouping and conditioning work just as before and can be used to see the relationship
between sepal length and sepal width broken down by species of iris plant.
With large data set, it can be helpful to make the dots semi-transparent so it is
easier to see where there are overlaps.  This is done with \argument{alpha}.
We can also make the dots smaller (or larger) using \argument{cex}.
<<xyplot2,fig.width=6,fig.height=3,tidy=FALSE>>=
xyplot( Sepal.Length ~ Sepal.Width | Species, data=iris, alpha=.6, cex=.5 )
xyplot( Sepal.Length ~ Sepal.Width, groups = Species, data=iris, alpha=.6, cex=.5, 
	   auto.key=TRUE )
@

\section{Exporting Plots}

You can save plots to files or copy them to the clipboard using the 
\tab{Export} menu in the \tab{Plots} tab.  It is quite simple to copy the 
plots to the clipboard and then paste them into a Word document, for example.
You can even adjust the height and width of the plot first to get it the 
shape you want.

\section{Reproducible Research}

When starting to learn to use \R\ for data analysis, it may be tempting to work 
by typing commands into the \R\ console directly, or maybe by copying and pasting commands
from some other source (for example, these notes, a website, etc.).

There are many reasons to avoid working this way, including:
\begin{itemize}
	\item It is tedious, unless there is very little to type, or to copy and paste.
	\item It is error-prone -- it's easy to copy too little or too much, or to grab the wrong thing,
		or to copy when you want to cut or cut when you want to copy.
	\item
		If something changes, you have to start all over.
	\item
		You have no record of what you did (unless you are an unusual person who
		takes detailed notes about everything you copied and pasted, or typed into the \R\ console).
\end{itemize}
So while copy and paste seems easy and convenient at first, it is not \emph{reproducible}.  Reproducible, here,
means something that can easily be repeated in exactly the same way (or with some desired modification), because
the exact procedure that was followed has been clearly documented in a format that is simple to access.
Reproducibility is important when projects are large, when it is important to have record of 
exactly what was done, or when the same analysis will be applied to multiple data sets (or a data set
that is growing over time).

\RStudio\ makes it easy to use techniques of reproducible research to create
documents that include text, \R\ commands, \R\ output, and \R\ graphics.  

\subsection{R Markdown}
One simple way to do reproducible work is to use a format called R Markdown.
Markdown is a simple
mark up language that allows for a few basic improvements on plain text
(section headers, bulleted lists, numbered lists, bold, italics, etc.)  R
Markdown adds the ability to mix in the \R\ stuff (\R\ commands and output,
including figures).  
The end product is an HTML file, so it is especially good for producing web 
documents.\footnote{You can actually mix in arbirary HTML and even css, so if you
are good at HTML, you can have quite a bit of control over how things look.  Here we
will focus on the basics.}

\subsubsection{Creating a new document}
To create a new R Markdown document in \RStudio, go to ``File", ``New File", then ``R Markdown":
\begin{center}
	\includegraphics[width=3in]{images/NewRMarkdown}
\end{center}

A small pop-up window will appear; for current purposes, you can select all the default
options (a Document, with HTML output format, with the Title and Author blanks
filled in or left blank, as you wish).
\begin{center}
  \includegraphics[width=3in]{images/NewRMarkdownPopup}
\end{center}

When you do this, a file editing pane will open with a template inserted.  If
you click on ``Knit HTML", \RStudio\ will turn this into an HTML file and
display it for you.  Give it a try.  You will be asked to name your file if you
haven't already done so.  If you are using the \RStudio\ server in a browser,
then your file will live on the server (``in the cloud'') rather than on your
computer.

If you look at the template file you will see that the file has two kinds of
sections.  Some of this file is just normal text (with some extra symbols to
make things bold, add in headings, etc.)  You can get a list of all of these
mark up options by selecting the ``Markdown Quick Reference" in the question
mark menu (at the top of the Markdown document in the editing pane).

\begin{center}
	\includegraphics[width=2in]{images/MardownQuickReference}
\end{center}

The second type of section is an \R\ code chunk.  These are colored differently to make them
easier to see.  You can insert a new code chunk by selecting ``Insert Chunk" from the ``Chunks" 
menu:
\begin{center}
	\includegraphics[width=2in]{images/InsertChunk}
\end{center}
\noindent
(You can also type \verb!```{r}! to begin and \verb!```! to end the code chunk if you would 
rather type.)
You can put any \R\ code in these code chunks and the results (text output or graphics) as well
as the \R\ code will be displayed in your HTML file.

In addition to knitting the document to HTML, you can do a number of other things that will
make your work more efficient.  In the ``Chunk" menu, you can choose to run a single chunk 
or all the chunks.  This will execute your commands in the console so you can make sure 
your \R\ code is working one chunk at a time.  There is also a ``run" button that allows you
to run just one line from within a chunk.

%There are options to do things like (a) run \R\ code without displayng it, (b) run \R\ code without
%displaying the output, (c) controling size of plots, etc., etc.  
%But for starting out, this is really all you need to know.

\subsection*{R Markdown files must be self-contained}
R Markdown files do not have access to things you have done in your console.  (This is good, else 
your document would change based on things not in the file.)  Within each R Markdown file, you must explicitly
load data, and require packages \emph{in the R Markdown file} in order to use them.  In this class,
this means that most of your R Markdown files will have a chunk near the beginning that loads required
packages and datasets.


\iffalse
\subsubsection{Creating an R Markdown document}
To create an R Markdown document, choose ``File", then ``New File", then ``R Markdown".  The file
will open with a template already loaded.   Take a quick look and you will see that most 
of this is easy to read.  You can see some text with a few extra symbols thrown in here and 
there and some chunks of \R\ code.
Now click on the "knit HTML" button and this document will be converted to HTML.

To create your own content, simply delete out the things you don't want or need
and replace them with your own content.  If you forget the markup, there is a help button
that will lead you to a quick reference guide.  To add a chunk of \R\ code, click on 
``Chunk" and then ``Insert Chunk" and put your \R\ code inside the chunk.

In addition to knitting the document to HTML, you can do a number of other things that will
make your work more efficient.  In the ``Chunk" menu, you can choose to run a single chunk 
or all the chunks.  This will execute your commands in the console so you can make sure 
your \R\ code is working one chunk at a time.  There is also a ``run" button that allows you
to run just one line from within a chunk.

\subsubsection{R Markdown files do not have access to the console environment}
One thing you need to remember about R Markdown documents is that the file must be self-contained.
This ensures that the document is portable.  It also means that the docuemnt does not have 
access to the things in your console environment.  All data must be loaded in the file.  
Similarly, all packages you use must also be loaded in the file.  If you start getting messages 
about objects not being found, one possible cause is that you have forgotten to get some 
data or some package loaded inside your file.  (Typos are another cause for these messages -- 
check your spelling and capitalization.)
\fi

\subsection*{Chunk options}
R Markdown provides a number of chunk options that control how \R\ code is processed.  
You can use them to do things like:
\begin{itemize}
	\item
		run the code without displaying it (good for polished reports -- your client doesn't want to see the code)
	\item
		show the code without running it -- mainly useful for demonstration purposes
	\item
		control the size and alignment of graphics
\end{itemize}
You can set default values for the chunk options and you can also override them in individual
chunks.  See the R Markdown help for more information about chunk options.

The default plots are often bigger than required.  The following chunk options are a place to 
start.  They can be adjusted as necessary.
<<eval=FALSE>>=
require(knitr)
opts_chunk$set( fig.width=5, fig.height=2, fig.align="center", fig.show="hold" )
@

\subsection{knitr/latex}
There is another system that produces PDFs by combining \LaTeX\ and \R, using the \R package
\pkg{knitr}.  This is the system
used to create this document; it gives much more control over document formatting.  The
quality is good enough for professional publishing.  If you already knwow \LaTeX, it is very
easy to learn.  If you don't know \LaTeX, then you need to learn the basics of \LaTeX\ to get
going, which is not covered in detail here.  If you are interested in learning more,
consult the documentation for the \pkg{knitr} package, or 
the \href{http://yihui.name/knitr/}{knitr website}.

\section{Customizing Graphics: A Few Bells and Whistles}
There are lots of arguments that control the appearance of plots created in \R.  Here are just a
few examples, some of which we have already seen.

\subsection{auto.key}
\option{auto.key=TRUE} turns on a simple legend for the grouping variable.  
(There are ways to have more control, if you need it.)
<<iris-xyplot-key,cache=TRUE,fig.width=2.6,fig.height=2.4>>=
xyplot(Sepal.Length ~ Sepal.Width, groups=Species, data=iris, 
	auto.key=TRUE)   
@

\subsection{alpha, cex}
Sometimes it is nice to have elements of a plot be partly transparent.  When
such elements overlap, they get darker, showing us where data are ``piling up."
Setting the \argument{alpha} argument to a value between 0 and 1 controls the
degree of transparency: 1 is completely opaque, 0 is invisible.  The
\argument{cex} argument controls ``character expansion" and can be used to make
the plotting ``characters" larger or smaller by specifying the scaling ratio.

Here is another example using data on 150 iris plants of three species.
<<iris-xyplot-alpha,cache=TRUE,fig.width=2.7,fig.height=2.2>>=
xyplot(Sepal.Length ~ Sepal.Width, groups=Species, data=iris, 
	auto.key=list(columns=3),
	alpha=.5,
	cex=1.3)   
@

\subsection*{main, sub, xlab, ylab}

You can add a title or subtitle, or change the default labels of the axes.
<<iris-xyplot-text,cache=TRUE,fig.width=3,fig.height=2.5>>=
xyplot(Sepal.Length ~ Sepal.Width, groups=Species, data=iris, 
	main="Some Iris Data",
	sub="(R. A. Fisher analysized this data in 1936)",
	xlab="sepal width (cm)",
	ylab="sepal length (cm)",
	alpha=.5,        
	auto.key=list(columns=3))   
@

\subsection*{layout}

\option{layout} can be used to control the arrangement of panels in a multi-panel
plot.  The format is
<<eval=FALSE>>=
layout=c(cols,rows)
@
where \code{cols} is the number of columns and \code{rows} is the number of 
rows.  (Columns first because that is the $x$-coordinate of the plot.)

\subsubsection*{lty, lwd, pch, col}
These can be used to change the line type, line width, plot symbol, and
color, respectively.  To specify multiples (one for each group), use the \function{c()} function
(to remember this function, remember that ``c" is for ``concatenate").  An example is below.


<<pch-lwd-lty,cache=TRUE,fig.width=3,fig.height=2.2>>=
densityplot( ~age, data=HELPrct, groups=sex, lty=1, lwd=c(2,4) )
histogram( ~ age, data=HELPrct, col='green')
@
<<col,fig.width=6,fig.height=2.6,tidy=FALSE>>=
# There are 25 numbered plot symbols
xyplot( Sepal.Length ~ Sepal.Width, data=iris, groups=Species, 
	    pch=c(1,2,3), col=c('brown', 'darkgreen', 'purple'), cex=.75 )  
@

Note: If you change the colors and symbols this way, they will \emph{not} match what is 
generated in the legend using \argument{auto.key=TRUE}.  So it can be better
to set these things in a different way if you are using \option{groups}.  
See below.

You can see a list of the hundreds of available color names using
\Rindex{colors()}%
<<colors,eval=FALSE>>=
colors()
@

\subsection{trellis.par.set()}
Default settings for lattice graphics are set using 
\function{trellis.par.set()}.
Don't like the default font sizes?  You can change them! For example,
change to a 7 point (base) font using

<<fontsize,eval=TRUE>>=
trellis.par.set(fontsize=list(text=7))    # base size for text is 7 point 
@

Nearly every feature of a lattice plot can be controlled: fonts, colors,
symbols, line thicknesses, colors, etc.  Rather than describe them all here,
we'll mention only that groups of these settings 
can be collected into a theme.  
\function{show.settings()} will show you what the current theme looks like.
Below are a few examples of changing the theme settings, then viewing the results.

<<themes-whitbg,cache=TRUE,fig.height=5,fig.width=6>>=
trellis.par.set(theme=col.whitebg())      # a theme in the lattice package
show.settings()
@
\newpage

<<themes-abd,cache=TRUE,fig.height=4.0,fig.width=6,out.height=".4\\textheight">>=
require(abd)
trellis.par.set(theme=col.abd())          # a theme in the abd package
show.settings()
@
<<themes-mosaic,cache=TRUE,fig.height=4,fig.width=6,out.height=".4\\textheight">>=
trellis.par.set(theme=col.mosaic)         # a theme in the mosaic package
show.settings()
@
<<themes-mosaicbw,cache=TRUE,fig.height=4,fig.width=6,out.height=".4\\textheight">>=
trellis.par.set(theme=col.mosaic(bw=TRUE)) # a b/w theme in the mosaic package
show.settings()
@

<<themes-abd-redo>>=
trellis.par.set(theme=col.mosaic())       # back to the mosaic theme
trellis.par.set(fontsize=list(text=9))    # and back to a 10 point font
@

Want to save your settings?
<<save-settings>>=
# save current settings
mySettings <- trellis.par.get()
# switch to abd defaults
trellis.par.set(theme=col.abd())
# switch back to my saved settings
trellis.par.set(mySettings)
@

\section{Getting Help in RStudio}

\subsection{The \RStudio\ help system}
There are several ways to get \RStudio\ to help you when you forget something.
Most objects in packages have help files that you can access by typing something 
like:
<<help-questionmark,eval=FALSE,tidy=FALSE>>=
?bargraph
?histogram
?HELPrct
@
You can search the help system using
<<help-GR,eval=FALSE>>=
help.search('Grand Rapids')    # Does R know anything about Grand Rapids?
@
This can be useful if you don't know the name of the function or data set you 
are looking for.

\subsection{Tab completion}
As you type the name of a function in \RStudio, you can hit the tab key and it
will show you a list of all the ways you could complete that name. After
you type the opening parenthesis, if you hit the tab key, you will get a list
of all the possible input arguments and (sometimes) some helpful hints about what they are.)

\subsection{History}
If you know you have done something before, but can't remember how, you can
search your history.  The history tab shows a list of recently executed
commands.  There is also a search bar to help you find things from longer ago.

\subsection{Error messages}
When things go wrong, \R\ tries to help you out by providing an error message.
Typos are probably the most common cause of errors: for example, you might
misspell a function or argument name, forget to close a set of parentheses or 
brackets, or misplace a comma.  
One common error message is illustrated below.
<<error-message>>=
fred <- 23
frd
@
The object \code{frd} is not found because it was mistyped.  It should have
been \code{fred}.  Another common mistake is forgetting to load required packages.
If you see an ``object not found'' message, check your
typing and check to make sure that the necessary packages have been loaded.
If you get an error and can't make sense of the message, you can try copying and pasting your
command and the error message and sending to me in an email. 

\section{Graphical Summaries -- Important Ideas}

\subsection{The Most Important Template}

The plots we have created have all following a single template

\begin{center}
	\Large 
	\texttt{ \fbox{\texttt{ goal }} ( \fbox{\texttt{ formula }}, data = \fbox{\texttt{ mydata }} ) }
\end{center}
We will see this same template used again for numerical summaries and linear and non-linear 
modeling as well, so it is is important to master it.

\begin{itemize}
	\item \texttt{goal}: The name of the function generally describes your goal, 
		the thing you want the computer to produce for you.  In the case of plotting,
		it is the name of the plot.  When we do numerical summaries it will be the 
		name of the numerical summary (mean, median, etc.).
	\item
		\texttt{formula}: For plotting, the formula describes which variables are 
		used on the x-axis, the y-axis and for conditioning.  The general scheme is
<<eval=FALSE>>=
y ~ x | z
@
		where \texttt{z} is the conditioning variable.  Sometimes \texttt{y} or \texttt{z} 
		are missing (but the right-hand side \texttt{x} must always be included in a formula).
	\item
		\texttt{data:} A data frame must be given in which the variables mentioned in
		the formula can be found.  Variables not found there will be looked for in the 
		enclosing environment.  Sometimes we will take advantage of this to avoid creating
		a temporary data frame just to make a quick plot, but generally it is best to have
		all the information inside a data frame.
\end{itemize}

\subsection{Patterns and Deviations from Patterns}
The goal of a statistical plot is to help us \emph{see} 
\begin{itemize}
\item 
potential patterns in the data, and 
\item
deviations from those patterns.  
\end{itemize}

\subsection{Different Plots for Different Kinds of Variables}
Graphical summaries can help us see the \emph{distribution} of a variable 
or the \emph{relationships} between two (or more) variables.  The type of plot
used will depend on the kinds of variables involved. Later, when we do more quantitative 
statistical analysis, we will see that the analysis we use will 
also depend on the kinds of variables involved, so this is an important idea.

\subsection{Side-by-side Plots and Overlays Can Reveal Importance of Additional Factors}
The \pkg{lattice} graphics plots make it particularly easy to generate plots that 
divide the data into groups and either produce a panel for each group (using \verb!|!)
or display each group in a different way (different colors or symbols, using 
the \argument{groups} argument).  These plots can reveal the 
possible influence of additional variables -- sometimes called covariates.

\subsection{Area = (relative) frequency}

Many plots are based on the key idea that our eyes are good at comparing areas.  Plots 
that use area (e.g., histograms, mosaic plots, bar charts, pie charts) should always obey
this principle
\begin{center}
\large
Area $=$ (relative) frequency
\end{center}
Plots that violate this principle can be deceptive and distort the true nature
of the data.  

\subsubsection*{An Example: Histogram with unequal bin widths}

It is possible to make histograms with bins that have different widths.
But in this case it is important that the height of the bars is chosen so 
that area (\emph{NOT height}) is proportional to frequency.  
Using height instead of area would distort the picture.

When unequal bin sizes are specified, \function{histogram()} by default chooses
the density scale:

<<hist-unequal-bins,fig.width=3,fig.height=2>>=
histogram( ~ Sepal.Length, data=iris, breaks=c(4,5,5.5,5.75,6,6.5,7,8,9))
@
The density scale is important.
It tells \R\ to use a scale such that 
the area (height $\times$ width) of the rectangles is equal to the relative frequency.
For example, the bar from 5.0 to 5.5 has width $\frac12$ and height about $0.36$, so 
the area is $0.18$, which means approximately 18\% of the sepal lengths are 
between 5.0 and 5.5.


It would be incorrect to choose \option{type="count"} or \option{type="proportion"} since
this distorts the picture of the data.  Fortunately, \R\ will warn you if you try:
%<<hist-unequal-bins-bad-echo,fig.width=3,fig.height=2,eval=FALSE>>=
% histogram( ~ Sepal.Length, data=iris, breaks=c(4,5,5.5,5.75,6,6.5,7,8,9), type='count')
% @
<<hist-unequal-bins-bad,fig.width=3,fig.height=2,echo=FALSE>>=
trellis.par.set(theme=col.fastR(bw=T))
histogram( ~ Sepal.Length, data=iris, breaks=c(4,5,5.5,5.75,6,6.5,7,8,9),type="count")
trellis.focus('panel',1,1)
grid.text(y=.7,'Never do this!', gp=gpar(col='red',cex=2,alpha=.6))
trellis.unfocus()
trellis.par.set(theme=col.mosaic())
@

Notice how different this looks.  Now the heights are equal to the relative
frequency, but this makes the wider bars have too much area.

\newpage

\section*{Exercises}

In your answers to these questions, include both the plots and the code you used 
to make them as well as any required discussion.  Once you have obtained a basic
plot that satisfies the requirements of the question, feel free to 
use some of the ``bells and whistles" to make the plots even better.

\begin{problem}
	Create a scatterplot using the two variables in the \dataframe{oldfaith}
	data frame.  What do we learn about Old Faithful eruptions from this plot?
\end{problem}

\begin{solution}
<<>>=
require(oldfaith)
xyplot(Duration ~ Interval, data=oldfaith)
@
The figure shows that the time between Old Faithful eruptions was generally longer after eruptions that were longer in duration.
\end{solution}

\begin{problem}
	Where do the data in the \dataframe{CPS85} data frame (in the 
	\pkg{mosaic} package) come from?  What are the observational 
	units?  How many are there?
\end{problem}

\begin{solution}
<<>>=
require(mosaic)
help(CPS85)
# or alternately:
?CPS85
#to find the number of observational units:
dim(CPS85)
#or
nrow(CPS85)
@
The CPS85 data comes from the Current Population Survey, which collects data on the US population between US Census years.  These data are from 1985. The observational units in this dataset are the individual persons surveyed.  There are 534 observational units (individual people) included in the dataset.
\end{solution}

\begin{problem}
	Choose a quantitative variable that interests you in the \dataframe{CPS85}
	data set.  Make an appropriate plot and comment on what you see.
\end{problem}

\begin{solution}
<<>>=
#an example:
histogram( ~ age , data=CPS85)
@
The CPS85 respondents range in age from under 20 to nearly 70 years old.  The distribution of ages of respondents is unimodal, but not symmetric -- there is a wider spread of ages at the high end of the distribution (in the right tail) than at the left. 
\end{solution}

\begin{problem}
	Choose a categorical variable that interests you in the \dataframe{CPS85}
	data set.  Make an appropriate plot and comment on what you see.
\end{problem}

\begin{solution}
<<>>=
#an example:
bargraph( ~ married , data=CPS85)
@
There were nearly twice as many married people as single people included in the 1985 CPS. 
\end{solution}


\begin{problem}
	Create a plot that displays two or more variables from the 
	\dataframe{CPS85} data.  At least one should be quantitative 
	and at least one should be categorical.
	Comment on what you can learn from your plot.
\end{problem}

\begin{solution}
<<>>=
#a simple example:
densityplot(~ age , groups=married , data=CPS85,
            auto.key=TRUE)
@
The single CPS85 respondents were mostly younger than the married ones, with single respondents over 50 making up a very small proportion of the dataset. 
\end{solution}

\begin{problem}
	Where do the data in the \dataframe{mpg} data frame (in the 
	\pkg{ggplot2} package) come from?  What are the observational 
	units?  How many are there?
\end{problem}

\begin{solution}
<<>>=
require(ggplot2)
data(mpg)
#or
?mpg
#to get the number of units:
#use information above, or
nrow(mpg)
#or
dim(mpg)
@
The mpg dataset contains information on fuel economy of several models of cars (car model years 1999 and 2008). The data were collected by the EPA, and are available on the web site \url{http://fueleconomy.gov}.  The observational units are car types (a particular model, from a particular year).  There are 234 observational units in the data set.
\end{solution}

\begin{problem}
	Choose a quantitative variable that interests you in the \dataframe{mpg}
	data set.  Make an appropriate plot and comment on what you see.
\end{problem}
\begin{solution}
<<>>=
#an example:
densityplot(~ cty , data=mpg, 
        xlab="Miles per Gallon (city)")
@
Most car models in the dataset got between about 15-20 miles per gallon in the city, and although the distribution of city fuel economy was slightly right-skewed, only a few models got better than 30 miles per gallon. 
\end{solution}

\begin{problem}
	Choose a categorical variable that interests you in the \dataframe{mpg}
	data set.  Make an appropriate plot and comment on what you see.
\end{problem}
\begin{solution}
<<>>=
#an example:
bargraph(~ class , data=mpg,
          xlab="Car Type")
@
SUV is the most common car type in the dataset, although pickups, compact cars, subcompact cars, and mid-size cars are also well-represented.  There are relatively few minivans and even fewer 2-seaters in the dataset.
\end{solution}

\begin{problem}
	Create a plot that displays two or more variables from the 
	\dataframe{mpg} data.  At least one should be quantitative 
	and at least one should be categorical.
	Comment on what you can learn from your plot.
\end{problem}

\begin{solution}
<<>>=
#an example:
histogram(~ hwy | class , data=mpg,
          xlab="Miles per Gallon (highway)",
          main="Highway fuel economy by car type")
@
Larger types of vehicles (like pickups, SUVs, and mini-vans) generally have lower fuel economy than smaller ones (like compact, subcompact, and midsize).
\end{solution}


\begin{problem}The file at \url{http://www.calvin.edu/~rpruim/data/Fires.csv}
	is a csv file containing data on wild lands fires in the US over a number of years.
You can load this data one of two ways.
\begin{itemize}
	\item
		Go to the workspace tab, select \tab{Import Data Set}, choose \tab{From Web URL...}
		and follow the instructions.
	\item
		Use the following command in \R:
<<>>=
Fires <- read.csv("http://www.calvin.edu/~rpruim/data/Fires.csv")
@
\end{itemize}
You can also use either of these methods to read from a file rather than from a
web URL, so this is a good way to get your own data into \R.
\begin{enumerate}
	\item
		The source for these data claim that data before a certain year should not be compared
		to data from after that year because the older data were computed a different way and
		are not considered as reliable.  What year is the break point?  Use graphs of the data 
		over time to estimate when something changed.
	\item
		You can trim the data to just the subset you want using \function{subset()}.  For 
		example, to get just the subset of years since 1966, you would use
<<>>=
Fires2 <- subset(Fires, Year > 1966)
@
		Be sure to use a new name for the subset data frame if you want to keep the original data available.

		Use \function{subset()} to create a data set that contains only the data from the new data regime (based on your answer in the previous problem).
	\item
		Using only the data from this smaller set, how would you describe what is happening with 
		fires over time?
\end{enumerate}
\end{problem}

\begin{solution}

<<>>=
#read in the data
Fires <- read.csv("http://www.calvin.edu/~rpruim/data/Fires.csv")
#get information about the dataset
head(Fires)
#plot number of fires over time
xyplot(Fires ~ Year, data=Fires)
#plot number of acres burned over time
xyplot(Acres ~ Year, data=Fires)
@
There is an abrupt change in the number of fires per year starting in 1983. (There is no such obvious break-point in the data on the number of acres burned, although you might argue that the number of acres burned began to increase in about 1990-95.)

<<>>=
#trim the data, keeping only data after 1982
Fires2 <- subset(Fires, Year > 1982)
#plot number of fires over time
xyplot(Fires ~ Year, data=Fires2)
#plot number of acres burned over time
xyplot(Acres ~ Year, data=Fires2)
#number of acres burned per fire over time
xyplot(Acres/Fires ~ Year, data=Fires2,
       ylab="Acres burned per fire")
@

The number of fires per year is relatively constant (excluding unusually low numbers in 1983-84), but the number of acres burned per year has increased over time.  Specifically, the fires have been larger in size (on average) since about 2000.
\end{solution}


\begin{problem}
	Use \R's help system to find out what the \variable{i1} and \variable{i2}
	variables are in the \dataframe{HELPrct} data frame.  Make histograms
	for each variable and comment on what you find out.  How would you describe
	the shape of these distributions?  Do you see any outliers (observations
	that don't seem to fit the pattern of the rest of the data)?  
\end{problem}

\begin{solution}
<<>>=
require(mosaic) #only if you have not yet done it this session!
?HELPrct
@
i1 is the average number of drinks consumed per day over the past 30 days, in standard units.  i2 is the maxium number of drinks per day (measured in the same way).  

<<>>=
histogram(~ i1, data=HELPrct, type="count")
histogram(~ i2, data=HELPrct, type="count")
@
The distributions of both i1 and i2 are heavily right-skewed. There are few observations of very heavy drinking (greater than about 75 for i1, or 100 for i2), but they are not necessarily obvious outliers (they fit the right-skewed pattern of the overall dataset).
\end{solution}

\begin{problem}
	Compare the distributions of \variable{i1} and \variable{i2} among men
	and women.
\end{problem}
\begin{solution}
<<>>=
densityplot( ~i1, groups=sex, data=HELPrct , auto.key=T)
densityplot( ~i2, groups=sex, data=HELPrct , auto.key=T)
@
Overall, the distribution for males is more right-skewed in both cases, indicating a greater proportion of males than females who drink more heavily.  The extreme right tail of the i1 (average consumption) distribution extends much further toward high values for males, again indicating more males than females with extremely high consumption.  Both female distributions also have a small second peak in density at higher consumption levels, perhaps indicating a subset of women who are consistently heavier drinkers. This bimodality is especially apparent in the i1 (average drinks per day) data.  
\end{solution}

\begin{problem}
	Compare the distributions of \variable{i1} and \variable{i2} among 
	the three \variable{substance} groups.
\end{problem}
\begin{solution}
<<>>=
densityplot( ~i1, groups=substance, data=HELPrct , auto.key=T)
densityplot( ~i2, groups=substance, data=HELPrct , auto.key=T)
@
<<>>=
densityplot( ~i1|sex, groups=substance, data=HELPrct , auto.key=T)
densityplot( ~i2|sex, groups=substance, data=HELPrct , auto.key=T)
@
Alcohol use is heavier among people whose primary substance of abuse is alcohol, whether we are considering i1 (average use) or i2 (maximum use). Among people whose primary drug of abuse is heroin or cocaine, the distribution of alcohol use among cocaine users is more right-skewed than among heroin users, suggesting that heavier alcohol consumption is more common in combination with cocaine than with heroin.  The observed patterns are relatively similar for males and females.
\end{solution}

\begin{problem}
	The \dataframe{SnowGR} contains historical data on snowfall in Grand Rapids, MI.
	The snowfall totals for November and December 2014 were 31 inches and 1 inch, respectively.
	\begin{enumerate}
		\item
			Create histograms of November and December snowfall totals.  How unusual were the snowfall totals we had in 2014?
		\item
			If there is very little snow in December, should we expect to have unusually much
			or little snow in February?  Make a scatter plot comparing December and February
			historic snowfall totals and comment on what you see there.
	\end{enumerate}
\end{problem}

\begin{solution}
<<>>=
histogram(~Nov, data=SnowGR)
histogram(~Dec, data=SnowGR)
@
November and December 2014 were both very unusual in terms of snowfall. 31 inches was a record high snowfall
total for November.  For December, tallies as low as or lower than 1 inch have been recorded before 2014, 
but were rare.

<<>>=
xyplot(Feb ~ Jan, data=SnowGR)
xyplot(Feb ~ Jan, data=SnowGR)
@
There is no clear relationship between December snowfall and February snowfall.  
Sometimes little snow falls in February after minimal snow in December, but sometimes
there is plenty of February snow despite little snow in December.  (So February 2015 might
yet be snowy!)
\end{solution}
\shipoutProblems

\ifsolutions
\ifsolutionslocal
\newpage
\section*{Solutions}
\shipoutSolutions
\fi
\fi
